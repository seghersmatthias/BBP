
\newpage
\section{Fase 2}
\label{sec:Fase2}

In \ref{sec:Fase1} fase 1 maakten we gebruik van ButtonPresses en JoystickMovements. We gaan nu nog een extra inputvariabele toevoegen. Er zijn spelletjes waar je soms eventjes niet kan spelen omdat er van level wordt veranderd of als je bijvoorbeeld Pacman speelt wordt er afgeteld van 3 naar 1 wanneer je dood geweest bent. Dit zijn dan 3 seconden dat er niets gebeurd is. Bij Mortal Kombat daarentegen wordt er meer gespeeld en moet er minder lang worden gewacht.
Vandaar dat er een kolom 'TotalTimeOfNoUseOfControls' is toegevoegd aan de dataset met random getallen die voor Mortal Kombat tussen 800 ms en 2500 ms liggen. Terwijl er bij Pacman gestart wordt vanaf 3000 ms tot 5000 ms.
Doordat er nu een extra variabele toegevoegd is, gaan we ervan uit dat de algoritmen er een beetje langer over zullen doen dan in de vorige fase. Nadat we die extra inputvariabele besproken hebben, gaan we de dataset nog een beetje realistischer te maken. Er zullen nog twee extra inputvariabelen toegevoegd worden namelijk de frequentie van de buttons en joystick per 20 seconden.  

\subsection{Logistische regressie}
\label{sec:Logistischeregressie-fase2}

Omdat we nog altijd met twee klassen werken, moet er bijna niets aan de implementatie veranderd worden. Enkel bij de declaratie van het object moet 'NumberOfInputs' naar 3 veranderd worden en vervolgens naar 5 wanneer we de kolommen 'ButtonPressesPer20Seconds' en 'JoystickmovementsPer20Seconds' in het algoritme willen betrekken. 

\subsubsection{Resultaten}
\paragraph{Snelheid van het algoritme} 
We beginnen bij onze eerste extra kolom, 'TotalTimeOfNoUseOfControls'. De snelheid van het algoritme werd opnieuw 20 keer gemeten. Het gemiddelde daarvan is 8,3405 ms. Dit is al dubbel zo lang als in de eerste implementatie. Dit komt doordat het verschil tussen Pacman en Mortal Kombat nu niet meer afhankelijk is van 2 duidelijk verschillende inputvariabelen, maar nu één extra is waar de verschillen dichter bij elkaar liggen.

In de volgende test voegen we de kolommen 'ButtonPressesPer20Seconds' en 'JoystickmovementsPer20Seconds' toe.  Verrassend genoeg is het gemiddelde met deze variabelen erbij slechts .7 ms gestegen. Dit kan verklaard worden doordat er een correlatie is tussen het aantal keer dat er op een knop gedrukt is in 1 minuut en de frequentie van de knoppen. Om de test te doen hebben we de correlatie tussen die twee kolommen berekend en die komt uit op 0.8010, wat wil zeggen dat er een sterk verband is. Doordat er zo'n sterk verband is, brengen die extra inputvariabelen geen meerwaarde aan de dataset. 

Een andere inputvariabele die we kunnen gebruiken is het aantal keer dat de speler 'dood' is geweest. In termen van Pacman is dit iedere keer wanneer hij opgegeten wordt. In geval van Mortal Kombat is dat het aantal keer de speler dood geschoten is geweest. In beide spelletjes is het mogelijk dat er geen enkele keer een 'dood' is geweest. Of als de speler een beginner is kan die vrij veel 'dood' gegaan zijn. Dit geldt voor beide spelletjes.  Wanneer we de gemiddelden meten met deze kolom erbij krijgen we een gemiddelde van 8,891 ms. De verklaring waarom het algoritme niet veel meer vertraagt is omdat de waarden van de eerste twee kolommen veel zwaarder doorwegen dan de laatste twee die nu toegevoegd geweest zijn. Dit geldt ook voor een 5de kolom die toegevoegd zal worden om de moeilijkheid nog een beetje te vergroten.  'Multiplayer' is een kolom met boolean waarden. Wanneer er 2 spelers tegen elkaar aan het spelen zijn zal die waarde op true staan, anders op false. Pacman zal altijd alleen gespeeld worden en dus zal die waarde altijd false zijn.  

Als we het programma debuggen kunnen we de coëfficiënten bekijken. Als we die uitschrijven voor de logistische regressie tot nu toe dan krijgen we volgend functievoorschrift. Daarin ziet u duidelijk dat de laatste 2 kolommen eigenlijk overbodig zijn. 
$$
{y(x0, x1, x2, x3, x4) = 255,958*x0 + 230,2784*x1 + -37,0513*x2 + 0,1878*x3 + 0,7306*x4 + 0,858}
$$
Zoals we in de sectie \ref{sec:Binaire-logistische-regressie} binaire logistische regressie hebben gezien moet de waarde van de functie hierboven nog verwerkt worden in de sigmoïdfunctie. 
 

\paragraph{F-score} 

Het tolerance property staat voor beide algoritmen op 0.1 wat aanduidt wanneer een leerproces mag stoppen. Als die waarde te laag staat ingesteld dan zal de hypothese overfitten. Als een hypothese overfitted is, dan wil dit zeggen dat hij te nauwkeurig wenst te voorspellen. Dit kan leiden tot een slechte generalisatie en dus slechte scores op de testdata. Als de Tolerance waarde te hoog is zal de hypothese te algemeen zijn en dus ook niet goed scoren. Een tolerance waarde van 0.1 is een goede keuze als ook de default waarde binnen het Accord-framework.
Logistische regressie blijft met deze waarde dan ook foutloos. De F-score is dus nog steeds 1.

%%Logistic regression code
\begin{figure}[]
	\renewcommand{\figurename}{Code}
\begin{lstlisting}
public static void StartLogisticRegression(double[][] input, int[] output)
{
       //LogisticRegression object initialiseren met 5 inputvariabelen
       LogisticRegression logisticRegression = new LogisticRegression()
       {
       		NumberOfInputs = 5
       };
		
		...
}

\end{lstlisting}
\caption{Implementatie binaire logistische regressie met 5 inputvariabelen}
\label{code:linaireRegressieTweeKlassenM5}
\end{figure}


\newpage
\subsection{Support Vector Machine}
\label{sec:supportvectormachineFase2}
Voor de support vector machine gaan we uiteraard dezelfde kolommen gebruiken als diegene die we voor logistische regressie hebben gebruikt. Als het aantal inputvariabelen relatief klein is tegenover het aantal trainingsvoorbeelden wordt er aangeraden om logistische regressie te gebruiken of een SVM zonder kernel. \autocite{courseraSVM}. Met geen kernel wordt de standaard lineaire kernel bedoeld. Dit is dan ook de kernel die in deze bachelorproef gebruikt wordt.
Ook voor dit algoritme moeten we niet veel aanpassen om meerdere inputvariabele in rekening te brengen. 

\subsubsection{Resultaten}
\paragraph{Snelheid van het algoritme} 
We starten met 'TotalTimeOfNoUseOfControls' toe te voegen. Het algoritme heeft daarvoor gemiddeld 39,3622 ms voor nodig gehad om een hypothese te bekomen. Dit is slechts een vermeerdering van $\pm$ 5 milliseconden. Ook voor de andere twee extra inputvariabelen bedraagt de vermeerdering bijna niets. Dit komt door de Tolerance waarde in het LineaarDualCoordinateDescent object. Die staat standaard ingesteld op 0.1 wat een goede keuze is omdat we niet willen dat onze hypothese 'overfitted' is. Bij SVM's kan de Tolerance waarde niet veranderd worden. Overfit is een term die gegeven wordt aan hypothesen die te nauwkeurig zijn wat uiteraard niet goed is. Zo kan het zijn dat nieuwe voorbeelden slecht gegeneraliseerd worden. 


\paragraph{F-score}

Ook de support vector machine is nog altijd feilloos in het voorspellen van de testdata. 


\subsection{Conclusie na fase 2}
Ondanks dat we ondertussen al gebruik maken van vijf inputvariabelen hebben de algoritmen het nog niet moeilijk om correcte voorspellingen te doen. Logistische regressie krijgt het zelfs niet eens lastiger. Na gemiddeld 8,891 ms is de hypothese al foutloos. De tolerance staat voor beide algoritmen op 0.1 wat aanduidt wanneer een leerproces mag stoppen. Als die waarde te laag staat ingesteld dan zal de hypothese overfitten. Als een hypothese overfitted is, dan wil dit zeggen dat hij te nauwkeurig wil voorspellen. Dit kan leiden tot een slechte generalisatie en dus slechte scores op de testdata. Als de Tolerance waarde te hoog is zal de hypothese te algemeen zijn en dus ook niet goed scoren. 