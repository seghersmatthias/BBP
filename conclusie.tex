%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}
\label{ch:conclusie}

%% TODO: Trek een duidelijke conclusie, in de vorm van een antwoord op de
%% onderzoeksvra(a)g(en). Wat was jouw bijdrage aan het onderzoeksdomein en
%% hoe biedt dit meerwaarde aan het vakgebied/doelgroep? Reflecteer kritisch
%% over het resultaat. Had je deze uitkomst verwacht? Zijn er zaken die nog
%% niet duidelijk zijn? Heeft het ondezoek geleid tot nieuwe vragen die
%% uitnodigen tot verder onderzoek?

%\lipsum[76-80]

Gedurende dit onderzoek zijn we van nul gestart. De eerste belangrijke stap was de juiste algoritmen kiezen. Aangezien ieder algoritme zijn eigen eigenschappen heeft was het niet mogelijk om twee willekeurige algoritmen te kiezen. Doordat we in bezit zijn van een dataset kon er gebruik gemaakt worden van gesuperviseerde algoritmen. Logistische regressie en support vector machines vallen onder dit type. Nadat de werking van de algoritmen besproken werd kon de applicatie ge√Ømplementeerd worden.

De implementatie werd in verschillende fasen opgesplitst zodat er telkens een korte analyse kon gemaakt worden. Tijdens de eerste fase wilden we voorspelling maken tussen Pacman en Mortal Kombat op basis van de 'ButtonPresses' en 'JoystickMovements'. Beide algoritmen hadden geen enkele fout gemaakt op de testdataset. Logistische regressie was wel ongeveer 6 keer sneller dan de support vector machine.
Daarna hebben we nog enkele inputparameters toegevoegd namelijk 'TotalTimeOfNoUseOfControls', 'AmountOfDeads' en 'Multiplayer'. Om een foutloze hypothese te krijgen met logistische regressie duurde het net niet dubbel zolang als de eerste fase die 4,5487 ms nodig had. Aangezien er meer dan een verdubbeling van aantal inputparameters gebeurd is zou u verwachten dat het algoritme ook meer dan dubbel zolang zou duren. Dit is in dit geval niet zo. Aangezien de eerste twee inputparameters zo'n duidelijk verschil maken tussen de spelletjes geven zij ook de grootste doorslag in de hypothese. Daarom is het niet nodig om de andere parameters verder te optimaliseren. Deze logica is ook van toepassing bij support vector machines. SVMs hebben slechts $\pm$ 8 ms extra nodig bovenop de 34,4823 ms van de eerste fase om een goede hypothese te bekomen. 
De F-score na de tweede fase was nog steeds 1 omdat de algoritmen foutloos bleven. Dit heeft ook te maken met het duidelijke verschil tussen 'ButtonPresses' en 'JoystickMovements'. Deze kolommen hebben de grootste doorslag waarden in de hypothese. Hieronder zien we de hypothese van logistische regressie. Als we die bekijken zien we ook duidelijk dat de eerste twee inputparameters een veel grotere factor hebben dan de overige. 
$$
y(x0, x1, x2, x3, x4) = 255,958*x0\:+\:230,2784*x1\:+\:-37,0513*x2\:+\:0,1878*x3\:+\:0,7306*x4\:+\:0,858
$$

Tijdens de derde fase werd er een 3de spel toegevoegd. Tetris is een spel die enkel gebruik maakt van de knoppen. Die manier van spelen is nog iets helemaal anders dan Pacman of Mortal Combat. Om foutloze voorspellingen met vijf input vectors te maken heeft logistische regressie 28,9126 ms nodig om te leren. De Support Vector Machine heeft maar liefst 135,0301ms nodig. Logistische regressie maakt 7 fouten op de 150 voorbeelden van de dataset. SVMs doen het op dit vlak beter met slechts 2 foutieve voorspellingen. Dit was de eerste fase met meerdere klassen de volgende stap zal er een vierde klasse toegevoegd worden zodat we een algemenere conclusie kunnen maken. 

Het vierde spel is Arkanoid dit is zeer gelijkaardig met Pacman. Arkanoid maakt ook enkel gebruik van de joystick maar het aantal bewegingen zijn veel minder. In deze fase van het onderzoek konden beide algoritmen geen foutloze voorspellingen meer doen. Nu meten we de snelheid wanneer het algoritme zijn optimale hypothese heeft. Dit wil zeggen de hypothese met het minst fouten. Voor logistische regressie is dit na 54 iteraties. Op de 200 voorbeelden worden er dan slechts 3 fouten gemaakt. Het leren van die hypothese duurt 29,8291 ms. Voor de SVM maakt de optimale hypothese gemiddeld 8 fouten en heeft 169,4067 ms nodig. 
Momenteel lijkt logistische regressie dan ook de beste keuze. Het probleem aan deze methode is dat de hypothese overfitted is omdat die zodanig perfect wil zijn zodat er min mogelijk aantal foute voorspellingen zijn. Een hypothese moet net generaliseren. 
Met een gegeneraliseerde hypothese maakt logistische regressie 19 foutieve voorspellingen  terwijl SVM maar 12 fouten maakt op de hele dataset. Support Vector Machine maakt enkel fouten tussen Arkanoid en Pacman omdat die op elkaar gelijken. Dit in tegenstelling tot logistische regressie want daar worden 10 van de 19 fouten gemaakt tussen ander klassen.